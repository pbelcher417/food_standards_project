name: Run standard_filesystem pipeline from food_hygiene__gcs_bq_pipeline.py
'on':
  schedule:
  - cron: 0 2 * * *
  workflow_dispatch: null
env:
  DESTINATION__BIGQUERY__DATASET_NAME: food_standards
  DESTINATION__BIGQUERY__LOCATION: US
  DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID: food-standards-project
  DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL: food-standards-etl-service-acc@food-standards-project.iam.gserviceaccount.com
  SOURCES__FILESYSTEM__CREDENTIALS__PROJECT_ID: food-standards-project
  SOURCES__FILESYSTEM__CREDENTIALS__CLIENT_EMAIL: food-standards-etl-service-acc@food-standards-project.iam.gserviceaccount.com
  DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY: ${{ secrets.DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY }}
  SOURCES__FILESYSTEM__CREDENTIALS__PRIVATE_KEY: ${{ secrets.SOURCES__FILESYSTEM__CREDENTIALS__PRIVATE_KEY }}

jobs:
  maybe_skip:
    runs-on: ubuntu-latest
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
    - id: skip_check
      uses: fkirc/skip-duplicate-actions@v5
      with:
        concurrent_skipping: always
        skip_after_successful_duplicate: 'false'
        do_not_skip: '[]'

  extract_from_site:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: ubuntu-latest
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10.x
    - uses: syphar/restore-virtualenv@v1
      id: cache-virtualenv
      with:
        requirement_files: requirements_github_action.txt

    - uses: 'google-github-actions/auth@v2'
      with:
        credentials_json: '${{ secrets.DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_SERVICE_ACCOUNT_FILE }}' # Replace with the name of your GitHub Actions secret
      
    - uses: syphar/restore-pip-download-cache@v1
      if: steps.cache-virtualenv.outputs.cache-hit != 'true'
    - run: pip install -r requirements_github_action.txt
      if: steps.cache-virtualenv.outputs.cache-hit != 'true'
      
    - name: Run Authorities Extract
      run: cd 'food_standards_etl/food_standards_data_download' && python 'authorities_extract.py'

  run_pipeline:
    needs: 
      - maybe_skip
      - extract_from_site
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: ubuntu-latest
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10.x
    - uses: syphar/restore-virtualenv@v1
      id: cache-virtualenv
      with:
        requirement_files: requirements_github_action.txt
    - uses: syphar/restore-pip-download-cache@v1
      if: steps.cache-virtualenv.outputs.cache-hit != 'true'
    - run: pip install -r requirements_github_action.txt
      if: steps.cache-virtualenv.outputs.cache-hit != 'true'
    - name: Run pipeline script
      run: cd 'food_standards_etl/gcs_load_to_bigquery' && python 'food_hygiene__gcs_bq_pipeline.py'
